names(vect)
vect2 <- c(11, 2, NA)
vect2 with c(11, 2, NA)
names(vect2) <- c("foo", "bar", "norf")
identical(vect, vect2)
vect["bar"]
vect[c("foo", "bar")]
my_vector <- 1:20
my_vector
dim(my_vector)
length(my_vector)
dim(my_vector) <- c(4, 5)
dim(my_vector)
attributes(my_vector)
my_vector
class(my_vector)
my_matrix <- my_vector
?matrix
my_matrix2 <- matrix(1:20, nrow=4, ncol=5)
identical(my_matrix, my_matrix2)
patients<-c("Bill", "Gina", "Kelly", "Sean")
cbind(patients, my_matrix)
my_data <- data.frame(patients, my_matrix)
my_data
class(my_data)
cnames<-c("patient", "age", "weight", "bp", "rating", "test")
colname(my_data)<-cnames
colnames(my_data)<-cnames
my_data
getwd()
getwd()
mydata = read.csv("getdata_data_ss06hid.csv")
head(mydata,3)
names(mydata)
strsplit(names(mydata), [wgtp])
strsplit(names(mydata), wgtp)
strsplit(names(mydata), "wgtp")
myGDP = read.csv("getdata_data_GDP.csv")
head(myGDP, 3)
myGDP$Gross.domestic.product.2012
head(myGDP, 3)
myGDP$x.3
myGDP$x.3
myGDP$X.3
gsup(",", "", "1,200")
gsub(",", "", "1,200")
gsub(",", "", "1,200,000")
gsub(",", "", myGDP$X.3)
mean(gsub(",", "", myGDP$X.3))
gsub(",", "", myGDP$X.3)
!is.NaN(gsub(",", "", myGDP$X.3))
!is.NA(gsub(",", "", myGDP$X.3))
!is.nan(gsub(",", "", myGDP$X.3))
is.nan(gsub(",", "", myGDP$X.3))
gsub(",", "", myGDP$X.3)
as.numeric(gsub(",", "", myGDP$X.3))
my_num<-as.numeric(gsub(",", "", myGDP$X.3))
!is.na(ny_num)
!is.na(my_num)
my_num[!is.na(my_num)]
mean(my_num[!is.na(my_num)])
myGDP = read.csv("getdata_data_GDP.csv")
head(myGDP, 3)
my_num<-as.numeric(gsub(",", "", myGDP$X.3))
mean(my_num[!is.na(my_num)])
head(myGDP, 3)
head(myGDP, 6)
myGDP$X.3
head(myGDP, 6)
myGDP$X.2
countryNames <- myGDP$X.2
countryName
countryNames
grep("^United",countryNames), 3
grep("^United",countryNames)
grep("*United",countryNames)
library(quantmod)
install.packages("quantmod")
library(quantmod)
amzn = getSymbols("AMZN",auto.assign=FALSE)
sampleTimes = index(amzn)
head(sampleTimes,4)
class(head(sampleTimes,4))
as.Date(head(sampleTimes,4), "%Y")
as.character(head(sampleTimes,4), "%Y")
as.character(sampleTimes, "%Y")
as.character(sampleTimes, "%Y")["2012"]
as.character(sampleTimes, "%Y")[["2012"]
]
head(as.character(sampleTimes, "%Y"),5)
myYEAR <- as.character(sampleTimes, "%Y")
head(MyYEAR)
head(myYEAR)
names(myYEAR)
names(myYEAR)<-"year"
myYEAR[myYEAR$year=="2007"]
myYEAR[myYEAR=="2007"]
myYEAR[year=="2007"]
myYEAR[myYEAR=="2007"]
myYEAR[myYEAR=="2012"]
dim(myYEAR[myYEAR=="2012"])
lenght(myYEAR[myYEAR=="2012"])
length(myYEAR[myYEAR=="2012"])
head(as.character(sampleTimes, "%Y"),5)
myEDU = read.csv("getdata_data_EDSTATS_Country.csv")
head(myEDU)
names(myEDU)
names(myGDP)
head(myGDP,4)
head(myGDP,8)
head(myGDP,80)
head(myEDU,4)
myEDU$Special.Notes
grepl("d", "sf d xc")
grep("d", "sf d xc")
grepl("iscal", myEDU$Special.Notes)
myEDU[grepl("iscal", myEDU$Special.Notes)]
library(nlme)
library(lattice)
xyplot(weight ~ Time | Diet, BodyWeight)
BodyWeight
library(lattice)
library(datasets)
data(airquality)
p <- xyplot(Ozone ~ Wind | factor(Month), data = airquality)
p
str(p)
library(datasets)
data(airquality)
qplot(Wind, Ozone, data = airquality, facets = . ~ factor(Month))
library(ggplot2)
qplot(Wind, Ozone, data = airquality, facets = . ~ factor(Month))
qplot(Wind, Ozone, data = airquality)
qplot(Wind, Ozone, data = airquality, geom = "smooth")
airquality = transform(airquality, Month = factor(Month))
qplot(Wind, Ozone, data = airquality, facets = . ~ Month)
library(ggplot2)
g <- ggplot(movies, aes(votes, rating))
print(g)
ggplot(movies, aes(votes, rating))
ggplot(movies, aes(x=votes, y=rating))
ggplot(movies, aes(x=rating))
qplot(rating, data=movies)
ggplot(movies, aes(x=rating))
library(ggplot2)
qplot(votes, rating, data = movies)
qplot(votes, rating, data = movies) + stats_smooth("loess")
library(methods)
qplot(votes, rating, data = movies) + stats_smooth("loess")
qplot(votes, rating, data = movies) + geom_smooth()
qplot(votes, rating, data = movies, smooth = "loess")
qplot(votes, rating, data = movies, panel = panel.loess)
library(lattice)
xyplot(rating~votes)
qplot(votes, rating, data = movies, smooth = "loess")
qplot(votes, rating, data = movies) + geom_smooth()
data.loading <- function(tickers, start.date, end.date)
{
# Change the locale
sl <- Sys.setlocale(locale="US")
# Create the universe of dates
all.dates <- seq(as.Date(start.date), as.Date(end.date), by="day")
all.dates <- subset(all.dates,weekdays(all.dates) != "Sunday" & weekdays(all.dates) != "Saturday")
all.dates.char <- as.matrix(as.character(all.dates))
# Create sparse matrices
open <- matrix(NA, NROW(all.dates.char), length(tickers))
hi <- open
low <- open
close <- open
volume <- open
adj.close <- open
# Name the rows correctly
rownames(open) <- all.dates.char
rownames(hi) <- all.dates.char
rownames(low) <- all.dates.char
rownames(close) <- all.dates.char
rownames(volume) <- all.dates.char
rownames(adj.close) <- all.dates.char
# Split the start and end dates to be used in the ULR later on
splt <- unlist(strsplit(start.date, "-"))
a <- as.character(as.numeric(splt[2])-1)
b <- splt[3]
c <- splt[1]
splt <- unlist(strsplit(end.date, "-"))
d <- as.character(as.numeric(splt[2])-1)
e <- splt[3]
f <- splt[1]
# Create the two out of the three basic components for the URL loading
str1 <- "http://ichart.finance.yahoo.com/table.csv?s="
str3 <- paste("&a=", a, "&b=", b, "&c=", c, "&d=", d, "&e=", e, "&f=", f, "&g=d&ignore=.csv", sep="")
# Main loop for all assets
for (i in seq(1,length(tickers),1))
{
str2 <- tickers[i]
strx <- paste(str1,str2,str3,sep="")
x <- read.csv(strx)
datess <- as.matrix(x[1])
replacing <- match(datess, all.dates.char)
open[replacing,i] <- as.matrix(x[2])
hi[replacing,i] <- as.matrix(x[3])
low[replacing,i] <- as.matrix(x[4])
close[replacing,i] <- as.matrix(x[5])
volume[replacing,i] <- as.matrix(x[6])
adj.close[replacing,i] <- as.matrix(x[7])
}
# Name the cols correctly
colnames(open) <- tickers
colnames(hi) <- tickers
colnames(low) <- tickers
colnames(close) <- tickers
colnames(volume) <- tickers
colnames(adj.close) <- tickers
# Return the ouput
return(list(open=open, high=hi, low=low, close=close, volume=volume, adj.close=adj.close))
}
data.loading("GOOG", "07/01/2014", "07/15/2014")
data.loading("GOOG", "01/07/2014", "15/07/2014")
library(data.table)
library(ggplot2)
library(data.table)
library(ggplot2)
##Reading database files
NEI <- readRDS("summarySCC_PM25.rds")
getwd()
library(data.table)
library(ggplot2)
##Reading database files
NEI <- readRDS("summarySCC_PM25.rds")
NEI$year <- factor(NEI$year, levels=c('1999', '2002', '2005', '2008'))
##Subsetting Baltimore City and Los Angeles - fips == 24510, 06037
MD.onroad <- subset(NEI, fips == '24510' & type == 'ON-ROAD')
CA.onroad <- subset(NEI, fips == '06037' & type == 'ON-ROAD')
##Aggregating
MD.DF <- aggregate(MD.onroad[, 'Emissions'], by=list(MD.onroad$year), sum)
colnames(MD.DF) <- c('year', 'Emissions')
MD.DF$City <- paste(rep('Baltimore-MD', 4))
CA.DF <- aggregate(CA.onroad[, 'Emissions'], by=list(CA.onroad$year), sum)
colnames(CA.DF) <- c('year', 'Emissions')
CA.DF$City <- paste(rep('Los Angeles-CA', 4))
##Joining two DataFrames in one
DF <- as.data.frame(rbind(MD.DF, CA.DF))
NEI$year <- factor(NEI$year, levels=c('1999', '2002', '2005', '2008'))
##Subsetting Baltimore City and Los Angeles - fips == 24510, 06037
MD.onroad <- subset(NEI, fips == '24510' & type == 'ON-ROAD')
CA.onroad <- subset(NEI, fips == '06037' & type == 'ON-ROAD')
##Aggregating
MD.DF <- aggregate(MD.onroad[, 'Emissions'], by=list(MD.onroad$year), sum)
colnames(MD.DF) <- c('year', 'Emissions')
MD.DF$City <- paste(rep('Baltimore-MD', 4))
CA.DF <- aggregate(CA.onroad[, 'Emissions'], by=list(CA.onroad$year), sum)
colnames(CA.DF) <- c('year', 'Emissions')
CA.DF$City <- paste(rep('Los Angeles-CA', 4))
##Joining two DataFrames in one
DF <- as.data.frame(rbind(MD.DF, CA.DF))
ggplot(data=DF, aes(x=year, y=Emissions)) + geom_bar(aes(fill=year)) + guides(fill=F) +
ggtitle('Comparing Emissions from Motor Vehicle (On-Road) Sources\nBaltimore City-MD vs. Los Angeles-CA')  +
ylab(expression('PM'[2.5])) + xlab('Year') + theme(legend.position='none') + facet_grid(. ~ City) +
geom_text(aes(label=round(Emissions,0), size=1, hjust=0.5, vjust=-1))
dev.copy(png,'plot6.png')
dev.off()
NEI <- [];
NEI <- NA;
MD <- NA;
MD.onroad <- NA;
mydata <- NA;
library(psych)
install.packages("psych")
library(psych)
install.packages("(gridExtra)")
install.packages("gridExtra")
install.packages("pdflatex")
render
libraru(rmarkdown)
library(rmarkdown)
render
render("CourseProject-Part1.Rmd", "pdf_document")
getwd()
render("CourseProject-Part1.Rmd", "pdf_document")
library(pandoc)
install.packages("pandoc")
getwd()
setwd("C:/Documents and Settings/diogenes/PML/Coursera_ML_Project")
gc()
gc()
train <- read.csv("pml-training.csv")
library(ISLR)
install.packages("ISLR")
library(ISLR)
head(Wage)
library(caret)
nrow(Wage)
Wage <- subset(Wage,select=-c(logwage))
inTrain <- createDataPartition(y=Wage$wage,
p=0.7, list=FALSE)
training <- Wage[inTrain,]; testing <- Wage[-inTrain,]
modFit <- train(wage ~ ., method="gbm",data=training,verbose=FALSE)
modFit <- train(wage ~ ., method="gbm",data=training,verbose=FALSE)
print(modFit)
data(iris)
head(iris)
nrow(iris)
nrow(Wage)
iris.rf <- randomForest(Species ~ ., iris, ntree=50, norm.votes=FALSE)
install.packages("randomForest")
library(randomForest)
iris.rf <- randomForest(Species ~ ., iris, ntree=50, norm.votes=FALSE)
Wage.rf <- randomForest(wage ~ ., Wage, ntree=50, norm.votes=FALSE)
Wage.rf <- randomForest(wage ~ ., Wage, ntree=50, norm.votes=FALSE)
Wage.rf <- randomForest(wage ~ ., Wage, ntree=50, norm.votes=FALSE, nodesize=42)
Wage.rf <- randomForest(wage ~ ., Wage, ntree=50, norm.votes=FALSE)
train.rf <- randomForest(classe ~ ., train, ntree=50, norm.votes=FALSE, nodesize=42)
print(train.rf)
train.rf <- randomForest(classe ~ ., train, ntree=50, norm.votes=FALSE, nodesize=42, na.action=na.omit)
sapply(train, function(x) length(unique(x)))
sapply(train, class)
vtype<-sapply(train, class)
vrep<-sapply(train, function(x) length(unique(x)))
vrep
vrep{,]}
vrep[,]
vrep[,1]
vrep[1,]
vrep
cbind(vrep, vtype)
cbind(vrep, vtype)[vrep>51]
cbind(vrep, vtype)
cbind(vrep, vtype)[order(vrep),]
cbind(vrep, vtype)[order(vrep),]
cbind(vrep, vtype)[order(vrep),][which(vtype=='factor']
cbind(vrep, vtype)[which(vtype=='factor']
cbind(vrep, vtype)[order(vrep),][which(vtype=='factor')]
cbind(vrep, vtype)[order(vrep),][which(vtype=='factor'),]
cbind(vrep, vtype)[order(vrep),][which(vtype=='factor' & vrep > 52),]
c("12")
cint("12")
int("12")
as.numeric("12")
cbind(vrep, vtype)[order(vrep),][which(vtype=='factor' & as.numeric(vrep) > 52),]
cbind(vrep, vtype)[order(vrep),][which(vtype=="factor" & as.numeric(vrep) > 52),]
cbind(vrep, vtype)[which(vtype=="factor" & as.numeric(vrep) > 52),]
cbind(vrep, vtype)[which(vtype=="factor" & as.numeric(vrep) > 52),][order(vrep),]
cbind(vrep, vtype)[which(vtype=="factor" & as.numeric(vrep) > 52),]
head[train]
head(traing)
head(train)
head(train[-classe,])
head(train[!classe,])
head(train[-"classe",])
head(train[,-classe])
head(train[classe])
head(train(classe)
)
head(train$classe)
md <- lm(classe ~ ., data=train)
cbind(vrep, vtype)[which(!vtype=="factor",]
cbind(vrep, vtype)[which(vtype!=="factor",]
cbind(vrep, vtype)[which(vtype<>"factor",]
cbind(vrep, vtype)
ifelse(cbind(vrep, vtype)=="numeric",1,0)
ifelse(cbind(vrep, vtype)==("numeric" or "integer"),1,0)
ifelse(cbind(vrep, vtype)==("numeric") or cbind(vrep, vtype)=="integer"),1,0)
ifelse(cbind(vrep, vtype)=="numeric" or cbind(vrep, vtype)=="integer",1,0)
ifelse(cbind(vrep, vtype)=="numeric",1,0)
ifelse(cbind(vrep, vtype)=="numeric",1,0)
ifelse(cbind(vrep, vtype)=="numeric",1,0)$vtype
f<-ifelse(cbind(vrep, vtype)=="numeric",1,0)
f$vtype
f
head(f)
library(data.table)
library(caret)
library(ggplot2)
library(doMC)
library(knitr)
library(xtable)
library(randomForest)
install.packages("doMC")
install.packages("xtable")
library(data.table)
library(caret)
library(ggplot2)
library(doMC)
library(knitr)
library(xtable)
library(randomForest)
install.packages("doMC")
read.pml <- function(file) {
fread(file, na.strings=c("#DIV/0!", ""))
}
build.report <- function() {
knit2html("project.Rmd", "index.html")
}
raw.train <- read.pml("pml-training.csv")
raw.validation <- read.pml("pml-testing.csv")
set.seed(13)
## contains some NA values
na.cols <- raw.train[,sapply(.SD, function(x) any(is.na(x)))]
drop.columns <- function(x) {
x[,!c("V1", "user_name", "raw_timestamp_part_1", "raw_timestamp_part_2", "cvtd_timestamp", "new_window", "num_window"),with=F]
}
transform.features <- function(x) {
x[,classe:=factor(classe)]
}
## try only columns that have values
training.features <- drop.columns(raw.train[,eval(names(which(na.cols == F))),with=F])
write.pml.predictions <- function(x) {
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
submit.prediction <- function(x, validation) {
in.train <- createDataPartition(x$classe, p=.60, list=FALSE)
train <- x[in.train[,1]]
model.rf <- train(y=as.factor(train$classe), x=train[,!"classe",with=F], tuneGrid=data.frame(mtry=3), trControl=trainControl(method="none"), method="parRF")
write.pml.predictions(predict(model.rf, newdata=drop.columns(validation[,eval(names(which(na.cols == F))[-60]),with=F])))
}
in.train <- createDataPartition(training.features$classe, p=.60, list=FALSE)
train <- training.features[in.train[,1]]
test <- training.features[-in.train[,1]]
model.rf <- train(y=as.factor(train$classe), x=train[,!"classe",with=F], tuneGrid=data.frame(mtry=3), trControl=trainControl(method="none"), method="parRF")
model.rf <- train(y=as.factor(train$classe), x=train[,!"classe",with=F], tuneGrid=data.frame(mtry=3), trControl=trainControl(method="none"), method="rf")
gc()
gc()
gc()
gc()
gc()
gc()
gc()
gc()
model.rf <- train(y=as.factor(train$classe), x=train[,!"classe",with=F], tuneGrid=data.frame(mtry=3), trControl=trainControl(method="none"), method="rf")
gc()
gc()
model.rf <- train(y=as.factor(train$classe), x=train[,!"classe",with=F], tuneGrid=data.frame(mtry=3), trControl=trainControl(method="none"), method="rf")
read.pml <- function(file) {
fread(file, na.strings=c("#DIV/0!", ""))
}
build.report <- function() {
knit2html("project.Rmd", "index.html")
}
raw.train <- read.pml("pml-training.csv")
raw.validation <- read.pml("pml-testing.csv")
set.seed(13)
## contains some NA values
na.cols <- raw.train[,sapply(.SD, function(x) any(is.na(x)))]
drop.columns <- function(x) {
x[,!c("V1", "user_name", "raw_timestamp_part_1", "raw_timestamp_part_2", "cvtd_timestamp", "new_window", "num_window"),with=F]
}
transform.features <- function(x) {
x[,classe:=factor(classe)]
}
## try only columns that have values
training.features <- drop.columns(raw.train[,eval(names(which(na.cols == F))),with=F])
write.pml.predictions <- function(x) {
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
submit.prediction <- function(x, validation) {
in.train <- createDataPartition(x$classe, p=.60, list=FALSE)
train <- x[in.train[,1]]
model.rf <- train(y=as.factor(train$classe), x=train[,!"classe",with=F], tuneGrid=data.frame(mtry=3), trControl=trainControl(method="none"), method="parRF")
write.pml.predictions(predict(model.rf, newdata=drop.columns(validation[,eval(names(which(na.cols == F))[-60]),with=F])))
}
library(data.table)
library(caret)
library(ggplot2)
library(doMC)
library(knitr)
library(xtable)
library(randomForest)
read.pml <- function(file) {
fread(file, na.strings=c("#DIV/0!", ""))
}
in.train <- createDataPartition(training.features$classe, p=.60, list=FALSE)
train <- training.features[in.train[,1]]
test <- training.features[-in.train[,1]]
model.rf <- train(y=as.factor(train$classe), x=train[,!"classe",with=F], tuneGrid=data.frame(mtry=3), trControl=trainControl(method="none"), method="parRF")
model.rf <- train(y=as.factor(train$classe), x=train[,!"classe",with=F], tuneGrid=data.frame(mtry=3), trControl=trainControl(method="none"), method="rf")
confusionMatrix(predict(model.rf, newdata=transform.features(test)), factor(test$classe))
print(plot(varImp(model.rf, scale = FALSE)))
x <- raw.validation
x
x <- x[feature_set[feature_set!='classe']]
library(Hmisc)
x <- x[feature_set[feature_set!='classe']]
library(foreach)
x <- x[feature_set[feature_set!='classe']]
library(randomForest)
library(caret)
library(doParallel)
install.packages("doParallel")
x <- x[feature_set[feature_set!='classe']]
feature_set <- colnames(raw.train[colSums(is.na(raw.train)) == 0])[-(1:7)]
x <- x[feature_set[feature_set!='classe']]
feature_set
feature_set[feature_set!='classe']
x
x[feature_set[feature_set!='classe']]
keys(x)
key(x)
names(x)
answers <- predict(rf, newdata=x)
submit.prediction
submit.prediction()
write.pml.predictions(predict(model.rf, newdata=drop.columns(raw.validation[,eval(names(which(na.cols == F))[-60]),with=F])))
getwd()
c(1,
2)
